The numbers are not in order because of asynchronous writes.
Here‚Äôs what‚Äôs happening in your code:

const fs = require("node:fs");

(async()=>{
    console.time("writeMany");
    fs.open("test.txt", "w", (err, fd)=>{
        for(let i = 0; i < 1000000; i++){
            // fs.write is ASYNC, it queues the writes
            fs.write(fd, ` ${i} `, ()=>{})
        }
    })
    console.timeEnd("writeMany")
})();

Why out of order?

fs.write is non-blocking ‚Üí it sends the write request to the OS and immediately moves on.
The OS and Node.js event loop decide when each write actually completes.
Because you‚Äôre firing 1,000,000 async writes almost instantly, the order they finish is not guaranteed.
That‚Äôs why the numbers in your file appear jumbled.
How to fix it (make writes sequential)
You need to await each write or use the fs.promises API instead:


*****************************************************************

const fs = require("node:fs");

(async()=>{
    console.time("writeMany");
    fs.open("test.txt", "w", (err, fd)=>{
        for(let i = 0; i < 1000000; i++){
            fs.writeSync(fd, ` ${i} `)
        }
    })
    console.timeEnd("writeMany")

})()


Step 1: Open file

fs.open("test.txt", "w", callback)
The OS opens test.txt for writing.
Returns a file descriptor (fd), which is just a reference to this open file.

Step 2: Loop and buffer creation

for(let i = 0; i < 1000000; i++){
    fs.writeSync(fd, ` ${i} `)
}


Each iteration creates a temporary buffer from the string ` ${i} `.
That buffer is passed to the OS with the fd.
The OS copies the data into its page cache (RAM) for that file.
Key: This does not necessarily write to the physical disk immediately.

Step 3: OS page cache and flushing

The OS stores the data in RAM first (called the page cache).
The OS decides when to flush that data to the actual hard disk ‚Äî it could be:
When the buffer reaches a certain size
After some time interval
When the file is closed (fs.close(fd))
If you explicitly call fs.fsync(fd)
So, all 1,000,000 buffers are first copied to RAM, and then the OS writes them in chunks to the physical storage.

Step 4: Disk storage

Eventually, the OS writes the buffered data to the physical location of test.txt on your hard disk.
The file descriptor (fd) ensures the OS knows which file‚Äôs page cache the data belongs to.

‚úÖ Summary

test.txt opened ‚Üí get fd.
Each loop iteration ‚Üí create buffer ‚Üí pass to OS ‚Üí OS copies to RAM (page cache).
Data is gradually flushed from RAM ‚Üí hard disk.
Millions of small buffers do not all hit the disk individually, only after being cached and batched.



*****************************************************************************************************************************

const fs = require("node:fs");

(async()=>{
    console.time("writeMany");
    fs.open("test.txt", "w", (err, fd)=>{
        for(let i = 0; i < 1000000; i++){
            const buff = Buffer.from(` ${i} `, "utf-8")
            fs.write(fd, ` ${buff} `, ()=>{})
        }
    })
    console.timeEnd("writeMany")
})();

Step 1: What happens with Buffer.from(...)
Buffer.from(" ${i} ", "utf-8")
‚Üí Creates a Node.js Buffer object in userland (your JS memory / V8 heap).

That buffer holds the raw bytes of your string (" 123 " ‚Üí [32, 49, 50, 51, 32]).

So in the loop, you‚Äôre creating 1,000,000 JS Buffer objects.
They exist in Node‚Äôs heap memory (managed by V8), not yet in the OS page cache.

Step 2: What happens with fs.write(fd, data, cb)
fs.write accepts either a Buffer or a string.

In your code, you passed ` ${buff} `, which is actually a string like " <Buffer 32 33 34> ".
That means Node will internally convert this string into another Buffer before handing it off to the OS.

‚ö†Ô∏è So you‚Äôre making an extra conversion, wasting memory/CPU.

If you had passed the buff directly:


fs.write(fd, buff, ()=>{})
üëâ Node would just send the existing Buffer to the OS (no second buffer creation).

Step 3: OS + Page Cache
Once Node calls into libuv ‚Üí OS syscall ‚Üí the buffer data is copied into the OS page cache (RAM).
From then, the OS decides when to flush to disk.

Node‚Äôs buffer can be garbage collected once it‚Äôs no longer referenced, but the OS still has its copy in the page cache.

‚úÖ So to answer your question
Yes ‚Üí you are creating 1 million Node.js Buffers in JS memory.
Yes again ‚Üí by passing a template string instead of the buffer, Node internally creates another Buffer for the string " ${buff} ".
Then ‚Üí that data is copied into the page cache (separate, managed by the OS).
So you end up with 2 levels of buffering:
Node.js heap Buffers (temporary, per iteration).
OS Page Cache (persistent until flushed).

üëâ If your intent was efficiency, you should write:

fs.write(fd, buff, ()=>{})
instead of interpolating buff into a string. That way, you avoid creating millions of extra Buffers.


Memory flow step by step with a diagram for your case.

üß† Memory Flow (when using your code with Buffer.from and fs.write(fd, \ ${buff} `)`)

[Node.js JavaScript land]
  |
  | 1. Loop creates Buffers in V8 heap
  |    buff = Buffer.from(" 123 ", "utf-8")
  v
+------------------+
| V8 Heap (RAM)    |   ‚Üí stores Node Buffers (1M objects)
+------------------+
          |
          | 2. You interpolate `${buff}` ‚Üí string like " <Buffer 31 32 33> "
          v
+------------------+
| JS String (V8)   |   ‚Üí another object, later converted to bytes
+------------------+
          |
          | 3. fs.write gets the string ‚Üí internally makes a new Buffer
          v
+------------------+
| New Buffer       |   ‚Üí created by Node internally for write
+------------------+
          |
          | 4. libuv syscall ‚Üí hand buffer to OS
          v
+------------------+
| OS Kernel (syscall layer)
+------------------+
          |
          | 5. OS copies data into Page Cache (RAM managed by OS)
          v
+------------------+
| Page Cache       |   ‚Üí internal pool of memory in OS
+------------------+
          |
          | 6. Later, OS flushes chunks to disk
          v
+------------------+
| Disk (SSD/HDD)   |
+------------------+

‚ö° Key Notes:

Two avoidable copies happen in your version:
Buffer ‚Üí String interpolation ‚Üí New Buffer

The page cache is separate from Node.js memory ‚Äî it‚Äôs managed by the OS, not V8.

Once data is in the page cache, the OS guarantees it will eventually reach disk, but not instantly.

‚úÖ If you instead wrote:


fs.write(fd, buff, ()=>{})
The flow becomes shorter:


Buffer (V8 heap) ‚Üí syscall ‚Üí Page Cache ‚Üí Disk
(one copy fewer, faster, less memory waste).


***********************************************************************************************************
 the ‚Äúinternal pool memory‚Äù you‚Äôre thinking of in Node.js is different from the OS page cache. Let me separate them clearly:

1. Node.js internal Buffer pool (~8 KB chunks, not 4 GB)

When you do Buffer.alloc / Buffer.from, Node doesn‚Äôt always ask the OS for memory directly.
Instead, it manages an internal buffer pool in the V8 heap / process memory.
This pool is made of chunks (typically 8 KB each).
Small Buffers (< 4 KB) are usually slices of this pool.

Big Buffers get their own allocation.

‚ö†Ô∏è This is inside your Node.js process, limited by V8 heap settings (--max-old-space-size, usually ~4 GB on 64-bit).
So when you create 1,000,000 Buffers in your loop, they first live in this Node-managed memory, not in the OS page cache yet.

2. OS page cache (separate, outside Node)

This is managed entirely by the operating system kernel.
Every time Node (or any program) writes a file, the OS stores that data in page cache (RAM) before flushing it to disk.
The size of the page cache is not fixed at 4 GB ‚Äî it dynamically grows/shrinks depending on available system RAM.
Example: if you have 16 GB RAM, the OS might use 12 GB for page cache if needed.

3. So difference:
Feature	                    Node.js Buffer Pool (internal)	                                      OS Page Cache
Who manages it	                 Node.js / V8	                                             Operating System kernel
Where it lives	              Process memory (heap)                                      	System RAM (outside process)
Default size	       ~8 KB chunks, up to V8 heap (~4 GB max by default)	              Dynamically managed (can use most of free RAM)
Purpose	                     Efficient JS Buffer allocations	                          Speed up file I/O (batching, caching)
Lifecycle	                 Controlled by GC (garbage collector)	                    Controlled by OS (flushed to disk when needed)


‚úÖ Summary

The Node internal buffer pool = memory inside Node‚Äôs process (V8 heap), used for Buffer objects.
The OS page cache = memory outside Node, managed by the kernel, used to buffer file I/O.
So they are different layers of memory. Data passes through Node‚Äôs buffer pool ‚Üí syscall ‚Üí OS page cache ‚Üí disk.



#################################################################################################

üß© The code

(async () => {

  const fileHandle = await fs.open("test.txt", "w")

  for (let i = 0; i < 1000000; i++) {
    await fileHandle.write(` ${i} `)
  }

})();

üß† Step-by-step breakdown
1Ô∏è‚É£ Your JavaScript (userland)

For each iteration in the loop:

You call:

await fileHandle.write(` ${i} `)


The string ` ${i} ` is converted into a Buffer internally by Node.js.
(So yes, a new small Buffer is created each time.)

That Buffer + the file descriptor (inside fileHandle) are sent to libuv.

So you‚Äôre right up to this point:
‚úÖ ‚ÄúBuffer is created ‚Üí libuv calls the write system call with that buffer and filehandle.‚Äù

2Ô∏è‚É£ libuv layer (C code inside Node.js)

libuv takes the file descriptor (fd) and the pointer to the Buffer‚Äôs memory.

It then submits a write() system call to the OS (through the kernel).

In pseudocode:

write(fd, buffer_ptr, buffer_length);


Because await is used, Node.js pauses your JS execution until this write completes.
(Other async tasks in the event loop can still run, but this particular await waits.)

3Ô∏è‚É£ Operating System (Kernel space)

Now the kernel steps in:

The OS receives the write() syscall with the file descriptor, buffer pointer, and length.

The OS copies the data from user space (your Buffer) into kernel space (page cache).

‚úÖ So yes ‚Äî your understanding is correct:
The data is copied into the page cache (not directly to disk yet).

The kernel marks those memory pages as ‚Äúdirty‚Äù (meaning: data not yet flushed to disk).

The write() syscall returns to libuv once the copy into page cache is complete ‚Äî not when data is physically written to disk.

So your await fileHandle.write() completes as soon as the kernel has copied your buffer into the page cache.

4Ô∏è‚É£ Disk I/O (later)

At some later point, the OS decides (or fsync() forces) to flush those dirty pages to the physical disk.
This is done asynchronously by the OS ‚Äî you don‚Äôt wait for it in your JS code.

‚öôÔ∏è In short:
Step	               Component	                What happens

1	                     JS	                 Creates buffer from string
2	                   libuv	              Calls write() system call
3	                    Kernel	                 Copies buffer ‚Üí page cache
4	                Kernel (later)	            Flushes page cache ‚Üí disk (async)